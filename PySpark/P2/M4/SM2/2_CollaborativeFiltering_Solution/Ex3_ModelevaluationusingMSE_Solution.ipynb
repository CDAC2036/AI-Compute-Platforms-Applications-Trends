{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6d56d2b",
   "metadata": {},
   "source": [
    "# Model evaluation using MSE\n",
    "\n",
    "- After generating the predicted ratings from the test data using ALS model, in this final part of the exercise, you'll prepare the data for calculating Mean Square Error (MSE) of the model. The `MSE` is the average value of `(original rating – predicted rating)^2` for all users and indicates the absolute fit of the model to the data. To do this, first, you'll organize both the ratings and prediction RDDs to make a tuple of `((user, product), rating))`, then join the `ratings` RDD with `prediction` RDD and finally apply a squared difference function along with `mean()` to get the MSE.\n",
    "\n",
    "- Remember, you have a `SparkContext` `sc` available in your workspace. Also, `ratings_final` and `predictions` RDD are already available in your workspace.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b144d34c",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "- Organize `ratings` RDD to make `((user, product), rating)`.\n",
    "- Organize `predictions` RDD to make `((user, product), rating)`.\n",
    "- Join the `prediction` RDD with the `ratings` RDD.\n",
    "- Evaluate the model using MSE between original rating and predicted rating and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0de212f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialization\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/talentum/spark\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "# In below two lines, use /usr/bin/python2.7 if you want to use Python 2\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3.6\" \n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.7-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")\n",
    "\n",
    "# NOTE: Whichever package you want mention here.\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0 pyspark-shell' \n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.3 pyspark-shell'\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc0b6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrypoint 2.x\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Spark SQL basic example\").enableHiveSupport().getOrCreate()\n",
    "\n",
    "# On yarn:\n",
    "# spark = SparkSession.builder.appName(\"Spark SQL basic example\").enableHiveSupport().master(\"yarn\").getOrCreate()\n",
    "# specify .master(\"yarn\")\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1954714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=402, product=69069, rating=1.8120387613106268),\n",
       " Rating(user=443, product=5618, rating=4.936607631940907)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import Rating\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "\n",
    "file_path = \"file:///home/talentum/test-jupyter/P2/M4/SM2/Dataset/ratings.csv\"\n",
    "\n",
    "# Load the data into RDD\n",
    "data = sc.textFile(file_path) # 100004 records\n",
    "\n",
    "# Split the RDD \n",
    "ratings = data.map(lambda l: l.split(','))\n",
    "\n",
    "# Transform the ratings RDD \n",
    "ratings_final = ratings.map(lambda line: Rating(int(line[0]), int(line[1]), float(line[2])))\n",
    "\n",
    "# Split the data into training and test\n",
    "training_data, test_data = ratings_final.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Create the ALS model on the training data\n",
    "model = ALS.train(training_data, rank=10, iterations=10)\n",
    "\n",
    "# Drop the ratings column \n",
    "testdata_no_rating = test_data.map(lambda p: (p[0], p[1]))\n",
    "\n",
    "# Predict the model  \n",
    "predictions = model.predictAll(testdata_no_rating)\n",
    "\n",
    "# Print the first rows of the RDD\n",
    "predictions.take(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b545e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare ratings data\n",
    "rates = ratings_final.____(lambda r: ((r[0], r[1]), ____))\n",
    "\n",
    "# Prepare predictions data\n",
    "preds = predictions.____(lambda r: ((____, ____), ____))\n",
    "\n",
    "# Join the ratings data with predictions data\n",
    "rates_and_preds = rates.____(preds)\n",
    "\n",
    "# Calculate and print MSE\n",
    "MSE = rates_and_preds.____(lambda r: (r[1][0] - r[1]____)**2).mean()\n",
    "print(\"Mean Squared Error of the model for the test data = {:.2f}\".format(____))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dbe6b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error of the model for the test data = 1.33\n"
     ]
    }
   ],
   "source": [
    "# Prepare ratings data\n",
    "rates = ratings_final.map(lambda r: ((r[0], r[1]), r[2]))\n",
    "\n",
    "# Prepare predictions data\n",
    "preds = predictions.map(lambda r: ((r[0], r[1]), r[2]))\n",
    "\n",
    "# Join the ratings data with predictions data\n",
    "rates_and_preds = rates.join(preds)\n",
    "\n",
    "# Calculate and print MSE\n",
    "MSE = rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "print(\"Mean Squared Error of the model for the test data = {:.2f}\".format(MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b11eaca",
   "metadata": {},
   "source": [
    "> Hurray! You have successfully created a Movie Recommendation System using Apache Spark.\n",
    "> Note - The MSE is a measure of the quality of an estimator—it is always non-negative, and values closer to zero are better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
